{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7be203f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa018bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1000, 2), dtype=float32, numpy=\n",
       "array([[9.1636, 6.3339],\n",
       "       [8.3872, 1.6484],\n",
       "       [8.9726, 2.0461],\n",
       "       ...,\n",
       "       [8.2343, 1.5666],\n",
       "       [8.1887, 4.5177],\n",
       "       [8.5591, 5.1374]], dtype=float32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = tf.constant(np.loadtxt('Домашнее задание 3_вар2.txt'), dtype='float32')\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "441b0465",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KohonenNN(tf.Module):\n",
    "    def __init__(self, num_outputs):\n",
    "        super().__init__()\n",
    "        self.num_outputs = num_outputs\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.W = tf.Variable(self.norm(tf.constant(tf.random.uniform([self.num_outputs, int(input_shape[-1])]))), name=\"kernel\")\n",
    "    \n",
    "    def __call__(self, inputs):\n",
    "        y = []\n",
    "        for X in self.norm(inputs):\n",
    "            y.append(tf.math.argmax(tf.math.reduce_sum(tf.math.multiply(X, self.W), axis=1)).numpy())\n",
    "        return tf.constant(y)\n",
    "    \n",
    "    def train(self, data_train, learning_rate=0.9, max_distance=2):\n",
    "        data_train = self.norm(data_train)\n",
    "        delt_max_distance = max_distance/(learning_rate/0.001)\n",
    "        epch = 0\n",
    "        sum_corr = 0\n",
    "        while(True):\n",
    "            for X in data_train:\n",
    "                prev_sum_corr = sum_corr\n",
    "                sum_corr = 0\n",
    "                ind_min_dist = tf.math.argmax(tf.math.reduce_sum(tf.math.multiply(X, self.W), axis=1))\n",
    "                for i in range(self.num_outputs):\n",
    "                    if tf.math.sqrt(tf.math.reduce_sum(tf.math.pow(tf.math.subtract(self.W[ind_min_dist], self.W[i]), 2))) <= max_distance:\n",
    "                        corr = tf.math.multiply(tf.math.subtract(X, self.W[i]), learning_rate)\n",
    "                        sum_corr += tf.abs(tf.math.reduce_sum(corr))\n",
    "                        new_w = tf.math.add(self.W[i], corr)\n",
    "                        self.W[i].assign(tf.math.divide(new_w, tf.math.sqrt(tf.math.reduce_sum(tf.math.pow(new_w, 2)))))\n",
    "                if (learning_rate-0.001) >= 0:\n",
    "                    learning_rate -= 0.001\n",
    "                if (max_distance-delt_max_distance) >= 0:\n",
    "                    max_distance -= delt_max_distance\n",
    "                if abs(sum_corr-prev_sum_corr) < 0.0000001:\n",
    "                    print('Learning rate: {}\\tMax distance: {}'.format(learning_rate, max_distance))\n",
    "                    return\n",
    "                print('Epoch: ', epch, '\\tLoss: ', abs(sum_corr-prev_sum_corr).numpy())\n",
    "                epch += 1\n",
    "                \n",
    "    def norm(self, inp):\n",
    "        denoms = tf.math.sqrt(tf.math.reduce_sum(tf.math.pow(inp, 2), axis=1, keepdims=True))\n",
    "        denoms = tf.concat([denoms, denoms], 1)\n",
    "        return tf.math.divide(inp, denoms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eddc18ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1000,), dtype=int32, numpy=\n",
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1])>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KohonenNN(2)\n",
    "knn.build(input_data.shape)\n",
    "y = knn(input_data)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "deea9e6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 \tLoss:  0.33999503\n",
      "Epoch:  1 \tLoss:  0.056310654\n",
      "Epoch:  2 \tLoss:  0.37959623\n",
      "Epoch:  3 \tLoss:  0.012293267\n",
      "Epoch:  4 \tLoss:  0.34490302\n",
      "Epoch:  5 \tLoss:  0.32157445\n",
      "Epoch:  6 \tLoss:  0.019386485\n",
      "Epoch:  7 \tLoss:  0.0006132452\n",
      "Epoch:  8 \tLoss:  0.0008732779\n",
      "Epoch:  9 \tLoss:  0.058221117\n",
      "Epoch:  10 \tLoss:  0.15591767\n",
      "Epoch:  11 \tLoss:  0.1355438\n",
      "Epoch:  12 \tLoss:  0.044130687\n",
      "Epoch:  13 \tLoss:  0.24971488\n",
      "Epoch:  14 \tLoss:  0.2738231\n",
      "Epoch:  15 \tLoss:  0.36459902\n",
      "Epoch:  16 \tLoss:  0.052055806\n",
      "Epoch:  17 \tLoss:  0.0053552687\n",
      "Epoch:  18 \tLoss:  0.089027\n",
      "Epoch:  19 \tLoss:  0.18334913\n",
      "Epoch:  20 \tLoss:  0.05831636\n",
      "Epoch:  21 \tLoss:  0.3818603\n",
      "Epoch:  22 \tLoss:  0.13044566\n",
      "Epoch:  23 \tLoss:  0.24970691\n",
      "Epoch:  24 \tLoss:  0.23452137\n",
      "Epoch:  25 \tLoss:  0.0033205599\n",
      "Epoch:  26 \tLoss:  0.0807683\n",
      "Epoch:  27 \tLoss:  0.2689737\n",
      "Epoch:  28 \tLoss:  0.2644731\n",
      "Epoch:  29 \tLoss:  0.054368734\n",
      "Epoch:  30 \tLoss:  0.24190101\n",
      "Epoch:  31 \tLoss:  0.03130568\n",
      "Epoch:  32 \tLoss:  0.034682855\n",
      "Epoch:  33 \tLoss:  0.09161106\n",
      "Epoch:  34 \tLoss:  0.16288099\n",
      "Epoch:  35 \tLoss:  0.2130099\n",
      "Epoch:  36 \tLoss:  0.020600066\n",
      "Epoch:  37 \tLoss:  0.008854002\n",
      "Epoch:  38 \tLoss:  0.010870051\n",
      "Epoch:  39 \tLoss:  0.3447832\n",
      "Epoch:  40 \tLoss:  0.33019152\n",
      "Epoch:  41 \tLoss:  0.30768666\n",
      "Epoch:  42 \tLoss:  0.30702096\n",
      "Epoch:  43 \tLoss:  0.022961855\n",
      "Epoch:  44 \tLoss:  0.04994943\n",
      "Epoch:  45 \tLoss:  0.2042924\n",
      "Epoch:  46 \tLoss:  0.23673344\n",
      "Epoch:  47 \tLoss:  0.2692584\n",
      "Epoch:  48 \tLoss:  0.27228078\n",
      "Epoch:  49 \tLoss:  0.29750952\n",
      "Epoch:  50 \tLoss:  0.2300023\n",
      "Epoch:  51 \tLoss:  0.29313654\n",
      "Epoch:  52 \tLoss:  0.38518903\n",
      "Epoch:  53 \tLoss:  0.04097496\n",
      "Epoch:  54 \tLoss:  0.2791789\n",
      "Epoch:  55 \tLoss:  0.013815969\n",
      "Epoch:  56 \tLoss:  0.04883614\n",
      "Epoch:  57 \tLoss:  0.3254707\n",
      "Epoch:  58 \tLoss:  0.0053042173\n",
      "Epoch:  59 \tLoss:  0.0008952301\n",
      "Epoch:  60 \tLoss:  0.24871257\n",
      "Epoch:  61 \tLoss:  0.024442047\n",
      "Epoch:  62 \tLoss:  0.2845203\n",
      "Epoch:  63 \tLoss:  0.29566634\n",
      "Epoch:  64 \tLoss:  0.2940401\n",
      "Epoch:  65 \tLoss:  0.0044495165\n",
      "Epoch:  66 \tLoss:  0.35478607\n",
      "Epoch:  67 \tLoss:  0.33733445\n",
      "Epoch:  68 \tLoss:  0.28321216\n",
      "Epoch:  69 \tLoss:  0.043920636\n",
      "Epoch:  70 \tLoss:  0.23568016\n",
      "Epoch:  71 \tLoss:  0.16584542\n",
      "Epoch:  72 \tLoss:  0.114246145\n",
      "Epoch:  73 \tLoss:  0.17632197\n",
      "Epoch:  74 \tLoss:  0.08776362\n",
      "Epoch:  75 \tLoss:  0.09359062\n",
      "Epoch:  76 \tLoss:  0.058756985\n",
      "Epoch:  77 \tLoss:  0.023093723\n",
      "Epoch:  78 \tLoss:  0.009007268\n",
      "Epoch:  79 \tLoss:  0.0020314604\n",
      "Epoch:  80 \tLoss:  0.28507832\n",
      "Epoch:  81 \tLoss:  0.22126493\n",
      "Epoch:  82 \tLoss:  0.08024463\n",
      "Epoch:  83 \tLoss:  0.2876098\n",
      "Epoch:  84 \tLoss:  0.019729316\n",
      "Epoch:  85 \tLoss:  0.00251773\n",
      "Epoch:  86 \tLoss:  0.009813428\n",
      "Epoch:  87 \tLoss:  0.20215811\n",
      "Epoch:  88 \tLoss:  0.090405576\n",
      "Epoch:  89 \tLoss:  0.30326742\n",
      "Epoch:  90 \tLoss:  0.26739374\n",
      "Epoch:  91 \tLoss:  0.29415497\n",
      "Epoch:  92 \tLoss:  0.235455\n",
      "Epoch:  93 \tLoss:  0.084765755\n",
      "Epoch:  94 \tLoss:  0.028492292\n",
      "Epoch:  95 \tLoss:  0.021023143\n",
      "Epoch:  96 \tLoss:  0.013409126\n",
      "Epoch:  97 \tLoss:  0.2507315\n",
      "Epoch:  98 \tLoss:  0.16300024\n",
      "Epoch:  99 \tLoss:  0.24623771\n",
      "Epoch:  100 \tLoss:  0.1540429\n",
      "Epoch:  101 \tLoss:  0.00046512485\n",
      "Epoch:  102 \tLoss:  0.0061847866\n",
      "Epoch:  103 \tLoss:  0.10109833\n",
      "Epoch:  104 \tLoss:  0.23464444\n",
      "Epoch:  105 \tLoss:  0.1998741\n",
      "Epoch:  106 \tLoss:  0.15390776\n",
      "Epoch:  107 \tLoss:  0.09116876\n",
      "Epoch:  108 \tLoss:  0.26440775\n",
      "Epoch:  109 \tLoss:  0.09306136\n",
      "Epoch:  110 \tLoss:  0.11849036\n",
      "Epoch:  111 \tLoss:  0.2565024\n",
      "Epoch:  112 \tLoss:  0.06580952\n",
      "Epoch:  113 \tLoss:  0.2512304\n",
      "Epoch:  114 \tLoss:  0.2840097\n",
      "Epoch:  115 \tLoss:  0.17717408\n",
      "Epoch:  116 \tLoss:  0.17129008\n",
      "Epoch:  117 \tLoss:  0.04904127\n",
      "Epoch:  118 \tLoss:  0.004165992\n",
      "Epoch:  119 \tLoss:  0.014931053\n",
      "Epoch:  120 \tLoss:  0.09396301\n",
      "Epoch:  121 \tLoss:  0.078415304\n",
      "Epoch:  122 \tLoss:  0.18548805\n",
      "Epoch:  123 \tLoss:  0.08363004\n",
      "Epoch:  124 \tLoss:  0.084209435\n",
      "Epoch:  125 \tLoss:  0.30019182\n",
      "Epoch:  126 \tLoss:  0.0057422817\n",
      "Epoch:  127 \tLoss:  0.30532444\n",
      "Epoch:  128 \tLoss:  0.023688769\n",
      "Epoch:  129 \tLoss:  0.01062065\n",
      "Epoch:  130 \tLoss:  0.23912507\n",
      "Epoch:  131 \tLoss:  0.029792845\n",
      "Epoch:  132 \tLoss:  0.03628847\n",
      "Epoch:  133 \tLoss:  0.2298066\n",
      "Epoch:  134 \tLoss:  0.023067523\n",
      "Epoch:  135 \tLoss:  0.2406903\n",
      "Epoch:  136 \tLoss:  0.09247334\n",
      "Epoch:  137 \tLoss:  0.12679565\n",
      "Epoch:  138 \tLoss:  0.025978245\n",
      "Epoch:  139 \tLoss:  0.23331016\n",
      "Epoch:  140 \tLoss:  0.15631641\n",
      "Epoch:  141 \tLoss:  0.055248365\n",
      "Epoch:  142 \tLoss:  0.22261447\n",
      "Epoch:  143 \tLoss:  0.03257823\n",
      "Epoch:  144 \tLoss:  0.019089878\n",
      "Epoch:  145 \tLoss:  0.0050441623\n",
      "Epoch:  146 \tLoss:  0.07349773\n",
      "Epoch:  147 \tLoss:  0.18057787\n",
      "Epoch:  148 \tLoss:  0.006935708\n",
      "Epoch:  149 \tLoss:  0.17534383\n",
      "Epoch:  150 \tLoss:  0.13548937\n",
      "Epoch:  151 \tLoss:  0.027471662\n",
      "Epoch:  152 \tLoss:  0.0312225\n",
      "Epoch:  153 \tLoss:  0.0134240575\n",
      "Epoch:  154 \tLoss:  0.0046430267\n",
      "Epoch:  155 \tLoss:  0.029542109\n",
      "Epoch:  156 \tLoss:  0.2684904\n",
      "Epoch:  157 \tLoss:  0.25651667\n",
      "Epoch:  158 \tLoss:  0.2591271\n",
      "Epoch:  159 \tLoss:  0.26032922\n",
      "Epoch:  160 \tLoss:  0.24020937\n",
      "Epoch:  161 \tLoss:  0.028550655\n",
      "Epoch:  162 \tLoss:  0.07137498\n",
      "Epoch:  163 \tLoss:  0.20294265\n",
      "Epoch:  164 \tLoss:  0.03643314\n",
      "Epoch:  165 \tLoss:  0.0047276616\n",
      "Epoch:  166 \tLoss:  0.18422076\n",
      "Epoch:  167 \tLoss:  0.14077152\n",
      "Epoch:  168 \tLoss:  0.09472825\n",
      "Epoch:  169 \tLoss:  0.04084985\n",
      "Epoch:  170 \tLoss:  0.27097788\n",
      "Epoch:  171 \tLoss:  0.3091077\n",
      "Epoch:  172 \tLoss:  0.0098442845\n",
      "Epoch:  173 \tLoss:  0.19611949\n",
      "Epoch:  174 \tLoss:  0.065386444\n",
      "Epoch:  175 \tLoss:  0.051839426\n",
      "Epoch:  176 \tLoss:  0.111134924\n",
      "Epoch:  177 \tLoss:  0.13618666\n",
      "Epoch:  178 \tLoss:  0.0074828714\n",
      "Epoch:  179 \tLoss:  0.063396096\n",
      "Epoch:  180 \tLoss:  0.07323056\n",
      "Epoch:  181 \tLoss:  0.13957179\n",
      "Epoch:  182 \tLoss:  0.05705169\n",
      "Epoch:  183 \tLoss:  0.15128264\n",
      "Epoch:  184 \tLoss:  0.0059917197\n",
      "Epoch:  185 \tLoss:  0.22299586\n",
      "Epoch:  186 \tLoss:  0.12582763\n",
      "Epoch:  187 \tLoss:  0.0674358\n",
      "Epoch:  188 \tLoss:  0.10037173\n",
      "Epoch:  189 \tLoss:  0.065564334\n",
      "Epoch:  190 \tLoss:  0.17990032\n",
      "Epoch:  191 \tLoss:  0.11166324\n",
      "Epoch:  192 \tLoss:  0.074360356\n",
      "Epoch:  193 \tLoss:  0.11310762\n",
      "Epoch:  194 \tLoss:  0.22043273\n",
      "Epoch:  195 \tLoss:  0.04071641\n",
      "Epoch:  196 \tLoss:  0.014377207\n",
      "Epoch:  197 \tLoss:  0.10425769\n",
      "Epoch:  198 \tLoss:  0.11373134\n",
      "Epoch:  199 \tLoss:  0.0029547513\n",
      "Epoch:  200 \tLoss:  0.22582501\n",
      "Epoch:  201 \tLoss:  0.018221654\n",
      "Epoch:  202 \tLoss:  0.031169754\n",
      "Epoch:  203 \tLoss:  0.006066814\n",
      "Epoch:  204 \tLoss:  0.013399996\n",
      "Epoch:  205 \tLoss:  0.0296168\n",
      "Epoch:  206 \tLoss:  0.21535592\n",
      "Epoch:  207 \tLoss:  0.07711059\n",
      "Epoch:  208 \tLoss:  0.0963095\n",
      "Epoch:  209 \tLoss:  0.22556517\n",
      "Epoch:  210 \tLoss:  0.043264434\n",
      "Epoch:  211 \tLoss:  0.019085735\n",
      "Epoch:  212 \tLoss:  0.2271167\n",
      "Epoch:  213 \tLoss:  0.22483778\n",
      "Epoch:  214 \tLoss:  0.19635078\n",
      "Epoch:  215 \tLoss:  0.02015303\n",
      "Epoch:  216 \tLoss:  0.065965176\n",
      "Epoch:  217 \tLoss:  0.10088919\n",
      "Epoch:  218 \tLoss:  0.08977771\n",
      "Epoch:  219 \tLoss:  0.13507175\n",
      "Epoch:  220 \tLoss:  0.16463879\n",
      "Epoch:  221 \tLoss:  0.02712661\n",
      "Epoch:  222 \tLoss:  0.06515695\n",
      "Epoch:  223 \tLoss:  0.12450557\n",
      "Epoch:  224 \tLoss:  0.081922114\n",
      "Epoch:  225 \tLoss:  0.006426407\n",
      "Epoch:  226 \tLoss:  0.2233302\n",
      "Epoch:  227 \tLoss:  0.15121713\n",
      "Epoch:  228 \tLoss:  0.05309677\n",
      "Epoch:  229 \tLoss:  0.26939723\n",
      "Epoch:  230 \tLoss:  0.18864664\n",
      "Epoch:  231 \tLoss:  0.06747422\n",
      "Epoch:  232 \tLoss:  0.15747234\n",
      "Epoch:  233 \tLoss:  0.047710955\n",
      "Epoch:  234 \tLoss:  0.15193307\n",
      "Epoch:  235 \tLoss:  0.018418252\n",
      "Epoch:  236 \tLoss:  0.24009754\n",
      "Epoch:  237 \tLoss:  0.18181114\n",
      "Epoch:  238 \tLoss:  0.13552171\n",
      "Epoch:  239 \tLoss:  0.0063431114\n",
      "Epoch:  240 \tLoss:  0.038773403\n",
      "Epoch:  241 \tLoss:  0.076050535\n",
      "Epoch:  242 \tLoss:  0.23755758\n",
      "Epoch:  243 \tLoss:  0.00356411\n",
      "Epoch:  244 \tLoss:  0.20270495\n",
      "Epoch:  245 \tLoss:  0.06899382\n",
      "Epoch:  246 \tLoss:  0.09179601\n",
      "Epoch:  247 \tLoss:  0.038270056\n",
      "Epoch:  248 \tLoss:  0.15601267\n",
      "Epoch:  249 \tLoss:  0.09405109\n",
      "Epoch:  250 \tLoss:  0.08728786\n",
      "Epoch:  251 \tLoss:  0.010285512\n",
      "Epoch:  252 \tLoss:  0.05318066\n",
      "Epoch:  253 \tLoss:  0.21353388\n",
      "Epoch:  254 \tLoss:  0.2250853\n",
      "Epoch:  255 \tLoss:  0.18828113\n",
      "Epoch:  256 \tLoss:  0.092921704\n",
      "Epoch:  257 \tLoss:  0.089089595\n",
      "Epoch:  258 \tLoss:  0.03836893\n",
      "Epoch:  259 \tLoss:  0.0026308335\n",
      "Epoch:  260 \tLoss:  0.046641372\n",
      "Epoch:  261 \tLoss:  0.2205046\n",
      "Epoch:  262 \tLoss:  0.05058302\n",
      "Epoch:  263 \tLoss:  0.053224675\n",
      "Epoch:  264 \tLoss:  0.080415584\n",
      "Epoch:  265 \tLoss:  0.016169477\n",
      "Epoch:  266 \tLoss:  0.20956618\n",
      "Epoch:  267 \tLoss:  0.0911676\n",
      "Epoch:  268 \tLoss:  0.09796396\n",
      "Epoch:  269 \tLoss:  0.17276084\n",
      "Epoch:  270 \tLoss:  0.10894367\n",
      "Epoch:  271 \tLoss:  0.026023448\n",
      "Epoch:  272 \tLoss:  0.08979049\n",
      "Epoch:  273 \tLoss:  0.04663489\n",
      "Epoch:  274 \tLoss:  0.031011986\n",
      "Epoch:  275 \tLoss:  0.17765519\n",
      "Epoch:  276 \tLoss:  0.05281566\n",
      "Epoch:  277 \tLoss:  0.014463469\n",
      "Epoch:  278 \tLoss:  0.11103644\n",
      "Epoch:  279 \tLoss:  0.053446736\n",
      "Epoch:  280 \tLoss:  0.21800084\n",
      "Epoch:  281 \tLoss:  0.08279948\n",
      "Epoch:  282 \tLoss:  0.040232897\n",
      "Epoch:  283 \tLoss:  0.027169377\n",
      "Epoch:  284 \tLoss:  0.11669909\n",
      "Epoch:  285 \tLoss:  0.10609489\n",
      "Epoch:  286 \tLoss:  0.08179895\n",
      "Epoch:  287 \tLoss:  0.075368755\n",
      "Epoch:  288 \tLoss:  0.20958152\n",
      "Epoch:  289 \tLoss:  0.09955554\n",
      "Epoch:  290 \tLoss:  0.049420863\n",
      "Epoch:  291 \tLoss:  0.20638342\n",
      "Epoch:  292 \tLoss:  0.040549964\n",
      "Epoch:  293 \tLoss:  0.07999256\n",
      "Epoch:  294 \tLoss:  0.044175655\n",
      "Epoch:  295 \tLoss:  0.08798547\n",
      "Epoch:  296 \tLoss:  0.08277564\n",
      "Epoch:  297 \tLoss:  0.029271275\n",
      "Epoch:  298 \tLoss:  0.01166223\n",
      "Epoch:  299 \tLoss:  0.0001924485\n",
      "Epoch:  300 \tLoss:  0.058379933\n",
      "Epoch:  301 \tLoss:  0.082791075\n",
      "Epoch:  302 \tLoss:  0.17604342\n",
      "Epoch:  303 \tLoss:  0.16520959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  304 \tLoss:  0.17184742\n",
      "Epoch:  305 \tLoss:  0.0611825\n",
      "Epoch:  306 \tLoss:  0.11617922\n",
      "Epoch:  307 \tLoss:  0.027531061\n",
      "Epoch:  308 \tLoss:  0.0040185167\n",
      "Epoch:  309 \tLoss:  0.026520273\n",
      "Epoch:  310 \tLoss:  0.020789428\n",
      "Epoch:  311 \tLoss:  0.020597419\n",
      "Epoch:  312 \tLoss:  0.011759482\n",
      "Epoch:  313 \tLoss:  0.018479064\n",
      "Epoch:  314 \tLoss:  0.21121016\n",
      "Epoch:  315 \tLoss:  0.090301216\n",
      "Epoch:  316 \tLoss:  0.026152804\n",
      "Epoch:  317 \tLoss:  0.08868271\n",
      "Epoch:  318 \tLoss:  0.0012228787\n",
      "Epoch:  319 \tLoss:  0.14257266\n",
      "Epoch:  320 \tLoss:  0.2183139\n",
      "Epoch:  321 \tLoss:  0.19116358\n",
      "Epoch:  322 \tLoss:  0.15445672\n",
      "Epoch:  323 \tLoss:  0.04406121\n",
      "Epoch:  324 \tLoss:  0.09198472\n",
      "Epoch:  325 \tLoss:  0.015263898\n",
      "Epoch:  326 \tLoss:  0.012815768\n",
      "Epoch:  327 \tLoss:  6.069243e-05\n",
      "Epoch:  328 \tLoss:  0.17853647\n",
      "Epoch:  329 \tLoss:  0.10304685\n",
      "Epoch:  330 \tLoss:  0.07053502\n",
      "Epoch:  331 \tLoss:  0.06681153\n",
      "Epoch:  332 \tLoss:  0.08417639\n",
      "Epoch:  333 \tLoss:  0.05075372\n",
      "Epoch:  334 \tLoss:  0.06295233\n",
      "Epoch:  335 \tLoss:  0.20842737\n",
      "Epoch:  336 \tLoss:  0.21363546\n",
      "Epoch:  337 \tLoss:  0.035122022\n",
      "Epoch:  338 \tLoss:  0.039351426\n",
      "Epoch:  339 \tLoss:  0.00030202046\n",
      "Epoch:  340 \tLoss:  0.007927636\n",
      "Epoch:  341 \tLoss:  0.19730072\n",
      "Epoch:  342 \tLoss:  0.11795546\n",
      "Epoch:  343 \tLoss:  0.08949125\n",
      "Epoch:  344 \tLoss:  0.20276918\n",
      "Epoch:  345 \tLoss:  0.13731712\n",
      "Epoch:  346 \tLoss:  0.09142183\n",
      "Epoch:  347 \tLoss:  0.016292334\n",
      "Epoch:  348 \tLoss:  0.023271784\n",
      "Epoch:  349 \tLoss:  0.08296102\n",
      "Epoch:  350 \tLoss:  0.02214896\n",
      "Epoch:  351 \tLoss:  0.00983177\n",
      "Epoch:  352 \tLoss:  0.1929885\n",
      "Epoch:  353 \tLoss:  0.08897996\n",
      "Epoch:  354 \tLoss:  0.10646196\n",
      "Epoch:  355 \tLoss:  0.09943716\n",
      "Epoch:  356 \tLoss:  0.03046374\n",
      "Epoch:  357 \tLoss:  0.044696525\n",
      "Epoch:  358 \tLoss:  0.07324366\n",
      "Epoch:  359 \tLoss:  0.01966734\n",
      "Epoch:  360 \tLoss:  0.011205772\n",
      "Epoch:  361 \tLoss:  0.0036619976\n",
      "Epoch:  362 \tLoss:  0.016017623\n",
      "Epoch:  363 \tLoss:  0.242174\n",
      "Epoch:  364 \tLoss:  0.1625461\n",
      "Epoch:  365 \tLoss:  0.021125406\n",
      "Epoch:  366 \tLoss:  0.042546596\n",
      "Epoch:  367 \tLoss:  0.16596574\n",
      "Epoch:  368 \tLoss:  0.027189821\n",
      "Epoch:  369 \tLoss:  0.11456898\n",
      "Epoch:  370 \tLoss:  0.11870107\n",
      "Epoch:  371 \tLoss:  0.06404809\n",
      "Epoch:  372 \tLoss:  0.025962941\n",
      "Epoch:  373 \tLoss:  0.011371084\n",
      "Epoch:  374 \tLoss:  0.009328343\n",
      "Epoch:  375 \tLoss:  0.04717204\n",
      "Epoch:  376 \tLoss:  0.005977011\n",
      "Epoch:  377 \tLoss:  5.1371753e-05\n",
      "Epoch:  378 \tLoss:  0.19922124\n",
      "Epoch:  379 \tLoss:  0.096628726\n",
      "Epoch:  380 \tLoss:  0.074484184\n",
      "Epoch:  381 \tLoss:  0.015299488\n",
      "Epoch:  382 \tLoss:  0.014015318\n",
      "Epoch:  383 \tLoss:  0.12567486\n",
      "Epoch:  384 \tLoss:  0.014128521\n",
      "Epoch:  385 \tLoss:  0.096369095\n",
      "Epoch:  386 \tLoss:  0.14851645\n",
      "Epoch:  387 \tLoss:  0.12093736\n",
      "Epoch:  388 \tLoss:  0.03385996\n",
      "Epoch:  389 \tLoss:  0.013630578\n",
      "Epoch:  390 \tLoss:  0.22680654\n",
      "Epoch:  391 \tLoss:  0.10787513\n",
      "Epoch:  392 \tLoss:  0.044090338\n",
      "Epoch:  393 \tLoss:  0.07229034\n",
      "Epoch:  394 \tLoss:  0.16245161\n",
      "Epoch:  395 \tLoss:  0.07618424\n",
      "Epoch:  396 \tLoss:  0.08132858\n",
      "Epoch:  397 \tLoss:  0.022864716\n",
      "Epoch:  398 \tLoss:  0.1817855\n",
      "Epoch:  399 \tLoss:  0.08979091\n",
      "Epoch:  400 \tLoss:  0.074088246\n",
      "Epoch:  401 \tLoss:  0.0038323663\n",
      "Epoch:  402 \tLoss:  0.13463195\n",
      "Epoch:  403 \tLoss:  0.09294772\n",
      "Epoch:  404 \tLoss:  0.06529467\n",
      "Epoch:  405 \tLoss:  0.0928686\n",
      "Epoch:  406 \tLoss:  0.08141056\n",
      "Epoch:  407 \tLoss:  0.065705836\n",
      "Epoch:  408 \tLoss:  0.025662612\n",
      "Epoch:  409 \tLoss:  0.14051118\n",
      "Epoch:  410 \tLoss:  0.14838907\n",
      "Epoch:  411 \tLoss:  0.089570224\n",
      "Epoch:  412 \tLoss:  0.0107611865\n",
      "Epoch:  413 \tLoss:  0.00594911\n",
      "Epoch:  414 \tLoss:  0.07809587\n",
      "Epoch:  415 \tLoss:  0.047178723\n",
      "Epoch:  416 \tLoss:  0.010176705\n",
      "Epoch:  417 \tLoss:  0.023323568\n",
      "Epoch:  418 \tLoss:  0.028805912\n",
      "Epoch:  419 \tLoss:  0.15205763\n",
      "Epoch:  420 \tLoss:  0.085107505\n",
      "Epoch:  421 \tLoss:  0.07096399\n",
      "Epoch:  422 \tLoss:  0.068782315\n",
      "Epoch:  423 \tLoss:  0.03690198\n",
      "Epoch:  424 \tLoss:  0.058656268\n",
      "Epoch:  425 \tLoss:  0.04952271\n",
      "Epoch:  426 \tLoss:  0.021051176\n",
      "Epoch:  427 \tLoss:  0.0011538379\n",
      "Epoch:  428 \tLoss:  0.12508202\n",
      "Epoch:  429 \tLoss:  0.05929999\n",
      "Epoch:  430 \tLoss:  0.0929596\n",
      "Epoch:  431 \tLoss:  0.01845375\n",
      "Epoch:  432 \tLoss:  0.018342825\n",
      "Epoch:  433 \tLoss:  0.0033634154\n",
      "Epoch:  434 \tLoss:  0.13911776\n",
      "Epoch:  435 \tLoss:  0.07930892\n",
      "Epoch:  436 \tLoss:  0.059259947\n",
      "Epoch:  437 \tLoss:  0.035214853\n",
      "Epoch:  438 \tLoss:  0.028173864\n",
      "Epoch:  439 \tLoss:  0.009301469\n",
      "Epoch:  440 \tLoss:  0.17589763\n",
      "Epoch:  441 \tLoss:  0.16939339\n",
      "Epoch:  442 \tLoss:  0.14120294\n",
      "Epoch:  443 \tLoss:  0.122353464\n",
      "Epoch:  444 \tLoss:  0.0729655\n",
      "Epoch:  445 \tLoss:  0.0036254972\n",
      "Epoch:  446 \tLoss:  0.06947204\n",
      "Epoch:  447 \tLoss:  0.09924253\n",
      "Epoch:  448 \tLoss:  0.11104315\n",
      "Epoch:  449 \tLoss:  0.020980097\n",
      "Epoch:  450 \tLoss:  0.0008505089\n",
      "Epoch:  451 \tLoss:  0.17249191\n",
      "Epoch:  452 \tLoss:  0.10516617\n",
      "Epoch:  453 \tLoss:  0.0303768\n",
      "Epoch:  454 \tLoss:  0.007945232\n",
      "Epoch:  455 \tLoss:  0.004239619\n",
      "Epoch:  456 \tLoss:  0.06632905\n",
      "Epoch:  457 \tLoss:  0.10935587\n",
      "Epoch:  458 \tLoss:  0.023299925\n",
      "Epoch:  459 \tLoss:  0.022372574\n",
      "Epoch:  460 \tLoss:  0.0010950491\n",
      "Epoch:  461 \tLoss:  0.02516912\n",
      "Epoch:  462 \tLoss:  0.040208705\n",
      "Epoch:  463 \tLoss:  0.09405675\n",
      "Epoch:  464 \tLoss:  0.06707265\n",
      "Epoch:  465 \tLoss:  0.0036990047\n",
      "Epoch:  466 \tLoss:  0.06618521\n",
      "Epoch:  467 \tLoss:  0.016093403\n",
      "Epoch:  468 \tLoss:  0.04151053\n",
      "Epoch:  469 \tLoss:  0.08229426\n",
      "Epoch:  470 \tLoss:  0.07315634\n",
      "Epoch:  471 \tLoss:  0.009660743\n",
      "Epoch:  472 \tLoss:  0.036864437\n",
      "Epoch:  473 \tLoss:  0.018960163\n",
      "Epoch:  474 \tLoss:  0.04222209\n",
      "Epoch:  475 \tLoss:  0.08340023\n",
      "Epoch:  476 \tLoss:  0.056743503\n",
      "Epoch:  477 \tLoss:  0.055662483\n",
      "Epoch:  478 \tLoss:  0.124683276\n",
      "Epoch:  479 \tLoss:  0.081528306\n",
      "Epoch:  480 \tLoss:  0.012622304\n",
      "Epoch:  481 \tLoss:  0.017343879\n",
      "Epoch:  482 \tLoss:  0.060387038\n",
      "Epoch:  483 \tLoss:  0.016960591\n",
      "Epoch:  484 \tLoss:  0.0054363683\n",
      "Epoch:  485 \tLoss:  0.020726122\n",
      "Epoch:  486 \tLoss:  0.00070764124\n",
      "Epoch:  487 \tLoss:  0.056291774\n",
      "Epoch:  488 \tLoss:  0.045524262\n",
      "Epoch:  489 \tLoss:  0.007209979\n",
      "Epoch:  490 \tLoss:  0.0221529\n",
      "Epoch:  491 \tLoss:  0.06001805\n",
      "Epoch:  492 \tLoss:  0.111840874\n",
      "Epoch:  493 \tLoss:  0.026491717\n",
      "Epoch:  494 \tLoss:  0.050902568\n",
      "Epoch:  495 \tLoss:  0.04326146\n",
      "Epoch:  496 \tLoss:  0.05228303\n",
      "Epoch:  497 \tLoss:  0.015356742\n",
      "Epoch:  498 \tLoss:  0.000781741\n",
      "Epoch:  499 \tLoss:  0.026324019\n",
      "Epoch:  500 \tLoss:  0.12637214\n",
      "Epoch:  501 \tLoss:  0.0597497\n",
      "Epoch:  502 \tLoss:  0.017283633\n",
      "Epoch:  503 \tLoss:  0.024017565\n",
      "Epoch:  504 \tLoss:  0.029407337\n",
      "Epoch:  505 \tLoss:  0.009895198\n",
      "Epoch:  506 \tLoss:  0.04239741\n",
      "Epoch:  507 \tLoss:  0.08276656\n",
      "Epoch:  508 \tLoss:  0.06465124\n",
      "Epoch:  509 \tLoss:  0.029785533\n",
      "Epoch:  510 \tLoss:  0.0180145\n",
      "Epoch:  511 \tLoss:  0.0011913814\n",
      "Epoch:  512 \tLoss:  0.009987943\n",
      "Epoch:  513 \tLoss:  0.0035495753\n",
      "Epoch:  514 \tLoss:  0.12380606\n",
      "Epoch:  515 \tLoss:  0.064819165\n",
      "Epoch:  516 \tLoss:  0.028390646\n",
      "Epoch:  517 \tLoss:  0.017353896\n",
      "Epoch:  518 \tLoss:  0.13998474\n",
      "Epoch:  519 \tLoss:  0.13704577\n",
      "Epoch:  520 \tLoss:  0.07430769\n",
      "Epoch:  521 \tLoss:  0.012604713\n",
      "Epoch:  522 \tLoss:  0.0073472857\n",
      "Epoch:  523 \tLoss:  0.06138226\n",
      "Epoch:  524 \tLoss:  0.02728437\n",
      "Epoch:  525 \tLoss:  0.122819126\n",
      "Epoch:  526 \tLoss:  0.05668956\n",
      "Epoch:  527 \tLoss:  0.015562918\n",
      "Epoch:  528 \tLoss:  0.02137144\n",
      "Epoch:  529 \tLoss:  0.0078834575\n",
      "Epoch:  530 \tLoss:  0.008387114\n",
      "Epoch:  531 \tLoss:  0.01237974\n",
      "Epoch:  532 \tLoss:  0.14152476\n",
      "Epoch:  533 \tLoss:  0.06882177\n",
      "Epoch:  534 \tLoss:  0.01926319\n",
      "Epoch:  535 \tLoss:  0.033135217\n",
      "Epoch:  536 \tLoss:  0.016766913\n",
      "Epoch:  537 \tLoss:  0.063885905\n",
      "Epoch:  538 \tLoss:  0.035812162\n",
      "Epoch:  539 \tLoss:  0.019696236\n",
      "Epoch:  540 \tLoss:  0.01872135\n",
      "Epoch:  541 \tLoss:  0.051346287\n",
      "Epoch:  542 \tLoss:  0.02935423\n",
      "Epoch:  543 \tLoss:  0.008713424\n",
      "Epoch:  544 \tLoss:  0.0063188076\n",
      "Epoch:  545 \tLoss:  0.004489042\n",
      "Epoch:  546 \tLoss:  0.004676521\n",
      "Epoch:  547 \tLoss:  0.02370692\n",
      "Epoch:  548 \tLoss:  0.0044131726\n",
      "Epoch:  549 \tLoss:  0.045703888\n",
      "Epoch:  550 \tLoss:  0.034295708\n",
      "Epoch:  551 \tLoss:  0.04418814\n",
      "Epoch:  552 \tLoss:  0.079689294\n",
      "Epoch:  553 \tLoss:  0.0040409416\n",
      "Epoch:  554 \tLoss:  0.023667581\n",
      "Epoch:  555 \tLoss:  0.02451127\n",
      "Epoch:  556 \tLoss:  0.039133027\n",
      "Epoch:  557 \tLoss:  0.03720903\n",
      "Epoch:  558 \tLoss:  0.095254526\n",
      "Epoch:  559 \tLoss:  0.047197513\n",
      "Epoch:  560 \tLoss:  0.042255454\n",
      "Epoch:  561 \tLoss:  0.0786792\n",
      "Epoch:  562 \tLoss:  0.01214987\n",
      "Epoch:  563 \tLoss:  0.030414402\n",
      "Epoch:  564 \tLoss:  0.038516756\n",
      "Epoch:  565 \tLoss:  0.01221117\n",
      "Epoch:  566 \tLoss:  0.07585399\n",
      "Epoch:  567 \tLoss:  0.07365673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  568 \tLoss:  0.009533789\n",
      "Epoch:  569 \tLoss:  0.08066094\n",
      "Epoch:  570 \tLoss:  0.062083878\n",
      "Epoch:  571 \tLoss:  0.050243974\n",
      "Epoch:  572 \tLoss:  0.0061701387\n",
      "Epoch:  573 \tLoss:  0.0034404472\n",
      "Epoch:  574 \tLoss:  0.056499735\n",
      "Epoch:  575 \tLoss:  0.02202833\n",
      "Epoch:  576 \tLoss:  0.032381486\n",
      "Epoch:  577 \tLoss:  0.06241899\n",
      "Epoch:  578 \tLoss:  0.00028722733\n",
      "Epoch:  579 \tLoss:  0.043774612\n",
      "Epoch:  580 \tLoss:  0.032205805\n",
      "Epoch:  581 \tLoss:  0.030930374\n",
      "Epoch:  582 \tLoss:  0.014084924\n",
      "Epoch:  583 \tLoss:  0.04322651\n",
      "Epoch:  584 \tLoss:  0.0060461685\n",
      "Epoch:  585 \tLoss:  0.02448196\n",
      "Epoch:  586 \tLoss:  0.0015198365\n",
      "Epoch:  587 \tLoss:  0.04218139\n",
      "Epoch:  588 \tLoss:  0.009207383\n",
      "Epoch:  589 \tLoss:  0.021637361\n",
      "Epoch:  590 \tLoss:  0.01181528\n",
      "Epoch:  591 \tLoss:  0.0078251995\n",
      "Epoch:  592 \tLoss:  0.08583759\n",
      "Epoch:  593 \tLoss:  0.07959697\n",
      "Epoch:  594 \tLoss:  0.057702474\n",
      "Epoch:  595 \tLoss:  0.01884593\n",
      "Epoch:  596 \tLoss:  0.066564485\n",
      "Epoch:  597 \tLoss:  0.020412307\n",
      "Epoch:  598 \tLoss:  0.047273032\n",
      "Epoch:  599 \tLoss:  0.030869424\n",
      "Epoch:  600 \tLoss:  0.029973201\n",
      "Epoch:  601 \tLoss:  0.06920351\n",
      "Epoch:  602 \tLoss:  0.06479423\n",
      "Epoch:  603 \tLoss:  0.06458506\n",
      "Epoch:  604 \tLoss:  0.039243504\n",
      "Epoch:  605 \tLoss:  0.040904336\n",
      "Epoch:  606 \tLoss:  0.046686318\n",
      "Epoch:  607 \tLoss:  0.0037046187\n",
      "Epoch:  608 \tLoss:  0.033521548\n",
      "Epoch:  609 \tLoss:  0.05508297\n",
      "Epoch:  610 \tLoss:  0.0037699174\n",
      "Epoch:  611 \tLoss:  0.0045034103\n",
      "Epoch:  612 \tLoss:  0.060436048\n",
      "Epoch:  613 \tLoss:  0.0070284754\n",
      "Epoch:  614 \tLoss:  0.039845265\n",
      "Epoch:  615 \tLoss:  0.024571512\n",
      "Epoch:  616 \tLoss:  0.045102563\n",
      "Epoch:  617 \tLoss:  0.0480367\n",
      "Epoch:  618 \tLoss:  0.0039702505\n",
      "Epoch:  619 \tLoss:  0.07578975\n",
      "Epoch:  620 \tLoss:  0.039975163\n",
      "Epoch:  621 \tLoss:  0.016777165\n",
      "Epoch:  622 \tLoss:  0.00014000759\n",
      "Epoch:  623 \tLoss:  0.019196507\n",
      "Epoch:  624 \tLoss:  0.065898255\n",
      "Epoch:  625 \tLoss:  0.068026\n",
      "Epoch:  626 \tLoss:  0.0016403515\n",
      "Epoch:  627 \tLoss:  0.06806787\n",
      "Epoch:  628 \tLoss:  0.059907597\n",
      "Epoch:  629 \tLoss:  0.05885126\n",
      "Epoch:  630 \tLoss:  0.035167903\n",
      "Epoch:  631 \tLoss:  0.012998439\n",
      "Epoch:  632 \tLoss:  0.014117051\n",
      "Epoch:  633 \tLoss:  0.008575063\n",
      "Epoch:  634 \tLoss:  0.009774379\n",
      "Epoch:  635 \tLoss:  0.031824704\n",
      "Epoch:  636 \tLoss:  0.027100079\n",
      "Epoch:  637 \tLoss:  0.059622478\n",
      "Epoch:  638 \tLoss:  0.048991352\n",
      "Epoch:  639 \tLoss:  0.009976076\n",
      "Epoch:  640 \tLoss:  0.029907476\n",
      "Epoch:  641 \tLoss:  0.0054182336\n",
      "Epoch:  642 \tLoss:  0.010823172\n",
      "Epoch:  643 \tLoss:  0.004715916\n",
      "Epoch:  644 \tLoss:  0.009073809\n",
      "Epoch:  645 \tLoss:  0.04176394\n",
      "Epoch:  646 \tLoss:  0.0555445\n",
      "Epoch:  647 \tLoss:  0.016059149\n",
      "Epoch:  648 \tLoss:  0.009341169\n",
      "Epoch:  649 \tLoss:  0.0363678\n",
      "Epoch:  650 \tLoss:  0.017981172\n",
      "Epoch:  651 \tLoss:  0.00604482\n",
      "Epoch:  652 \tLoss:  0.009139705\n",
      "Epoch:  653 \tLoss:  0.0048746243\n",
      "Epoch:  654 \tLoss:  0.03297968\n",
      "Epoch:  655 \tLoss:  0.025715593\n",
      "Epoch:  656 \tLoss:  0.004494179\n",
      "Epoch:  657 \tLoss:  0.01359598\n",
      "Epoch:  658 \tLoss:  0.051863465\n",
      "Epoch:  659 \tLoss:  0.026087843\n",
      "Epoch:  660 \tLoss:  0.0054761395\n",
      "Epoch:  661 \tLoss:  0.012478083\n",
      "Epoch:  662 \tLoss:  0.004955273\n",
      "Epoch:  663 \tLoss:  0.03854048\n",
      "Epoch:  664 \tLoss:  0.057191648\n",
      "Epoch:  665 \tLoss:  0.045716517\n",
      "Epoch:  666 \tLoss:  0.016076215\n",
      "Epoch:  667 \tLoss:  0.025266105\n",
      "Epoch:  668 \tLoss:  0.05544827\n",
      "Epoch:  669 \tLoss:  0.023176208\n",
      "Epoch:  670 \tLoss:  0.02385424\n",
      "Epoch:  671 \tLoss:  0.002870053\n",
      "Epoch:  672 \tLoss:  0.03200542\n",
      "Epoch:  673 \tLoss:  0.03023219\n",
      "Epoch:  674 \tLoss:  0.004386509\n",
      "Epoch:  675 \tLoss:  0.014728684\n",
      "Epoch:  676 \tLoss:  0.065963276\n",
      "Epoch:  677 \tLoss:  0.04734911\n",
      "Epoch:  678 \tLoss:  0.019342573\n",
      "Epoch:  679 \tLoss:  0.06331356\n",
      "Epoch:  680 \tLoss:  0.068202294\n",
      "Epoch:  681 \tLoss:  0.015968423\n",
      "Epoch:  682 \tLoss:  0.036562387\n",
      "Epoch:  683 \tLoss:  0.00097265095\n",
      "Epoch:  684 \tLoss:  0.033576615\n",
      "Epoch:  685 \tLoss:  0.013650872\n",
      "Epoch:  686 \tLoss:  0.024036014\n",
      "Epoch:  687 \tLoss:  0.007307755\n",
      "Epoch:  688 \tLoss:  0.05195452\n",
      "Epoch:  689 \tLoss:  0.032912795\n",
      "Epoch:  690 \tLoss:  0.013311937\n",
      "Epoch:  691 \tLoss:  0.021601213\n",
      "Epoch:  692 \tLoss:  0.015021002\n",
      "Epoch:  693 \tLoss:  0.0032853484\n",
      "Epoch:  694 \tLoss:  0.007992301\n",
      "Epoch:  695 \tLoss:  0.0065566152\n",
      "Epoch:  696 \tLoss:  0.008272216\n",
      "Epoch:  697 \tLoss:  0.008359481\n",
      "Epoch:  698 \tLoss:  0.0003474094\n",
      "Epoch:  699 \tLoss:  0.004769746\n",
      "Epoch:  700 \tLoss:  0.023333909\n",
      "Epoch:  701 \tLoss:  0.038067795\n",
      "Epoch:  702 \tLoss:  0.022562876\n",
      "Epoch:  703 \tLoss:  0.010415196\n",
      "Epoch:  704 \tLoss:  0.005543936\n",
      "Epoch:  705 \tLoss:  0.008832149\n",
      "Epoch:  706 \tLoss:  0.0464614\n",
      "Epoch:  707 \tLoss:  0.047438182\n",
      "Epoch:  708 \tLoss:  0.041489303\n",
      "Epoch:  709 \tLoss:  0.025549755\n",
      "Epoch:  710 \tLoss:  0.003365256\n",
      "Epoch:  711 \tLoss:  0.026113665\n",
      "Epoch:  712 \tLoss:  0.057312317\n",
      "Epoch:  713 \tLoss:  0.040509675\n",
      "Epoch:  714 \tLoss:  0.010881025\n",
      "Epoch:  715 \tLoss:  0.014082247\n",
      "Epoch:  716 \tLoss:  0.033032373\n",
      "Epoch:  717 \tLoss:  0.01549742\n",
      "Epoch:  718 \tLoss:  0.002138786\n",
      "Epoch:  719 \tLoss:  0.013848197\n",
      "Epoch:  720 \tLoss:  0.019187653\n",
      "Epoch:  721 \tLoss:  0.0029855724\n",
      "Epoch:  722 \tLoss:  0.01815622\n",
      "Epoch:  723 \tLoss:  0.0030336715\n",
      "Epoch:  724 \tLoss:  0.011705305\n",
      "Epoch:  725 \tLoss:  5.3506345e-05\n",
      "Epoch:  726 \tLoss:  0.008929547\n",
      "Epoch:  727 \tLoss:  0.006038245\n",
      "Epoch:  728 \tLoss:  0.001884494\n",
      "Epoch:  729 \tLoss:  0.00085802376\n",
      "Epoch:  730 \tLoss:  0.008973412\n",
      "Epoch:  731 \tLoss:  0.011567306\n",
      "Epoch:  732 \tLoss:  0.0055311546\n",
      "Epoch:  733 \tLoss:  0.0042384174\n",
      "Epoch:  734 \tLoss:  0.03586904\n",
      "Epoch:  735 \tLoss:  0.007242568\n",
      "Epoch:  736 \tLoss:  0.029956222\n",
      "Epoch:  737 \tLoss:  0.009771805\n",
      "Epoch:  738 \tLoss:  0.012836631\n",
      "Epoch:  739 \tLoss:  0.0029412434\n",
      "Epoch:  740 \tLoss:  0.0059376433\n",
      "Epoch:  741 \tLoss:  0.0181022\n",
      "Epoch:  742 \tLoss:  0.01036947\n",
      "Epoch:  743 \tLoss:  0.0063395146\n",
      "Epoch:  744 \tLoss:  0.0038349386\n",
      "Epoch:  745 \tLoss:  0.0047465414\n",
      "Epoch:  746 \tLoss:  0.015036594\n",
      "Epoch:  747 \tLoss:  0.0129289795\n",
      "Epoch:  748 \tLoss:  0.010945519\n",
      "Epoch:  749 \tLoss:  0.0014579557\n",
      "Epoch:  750 \tLoss:  0.0152091645\n",
      "Epoch:  751 \tLoss:  0.011915155\n",
      "Epoch:  752 \tLoss:  0.006138008\n",
      "Epoch:  753 \tLoss:  0.0029303133\n",
      "Epoch:  754 \tLoss:  0.0063892603\n",
      "Epoch:  755 \tLoss:  0.015499374\n",
      "Epoch:  756 \tLoss:  0.01006368\n",
      "Epoch:  757 \tLoss:  0.0015046857\n",
      "Epoch:  758 \tLoss:  0.009822579\n",
      "Epoch:  759 \tLoss:  0.0068926457\n",
      "Epoch:  760 \tLoss:  0.017564327\n",
      "Epoch:  761 \tLoss:  0.014720455\n",
      "Epoch:  762 \tLoss:  0.0039626323\n",
      "Epoch:  763 \tLoss:  0.0066169463\n",
      "Epoch:  764 \tLoss:  0.0008171499\n",
      "Epoch:  765 \tLoss:  0.019552462\n",
      "Epoch:  766 \tLoss:  0.008953731\n",
      "Epoch:  767 \tLoss:  0.008009449\n",
      "Epoch:  768 \tLoss:  0.0019271001\n",
      "Epoch:  769 \tLoss:  0.0021267198\n",
      "Epoch:  770 \tLoss:  0.008720584\n",
      "Epoch:  771 \tLoss:  0.0010100678\n",
      "Epoch:  772 \tLoss:  0.0062541068\n",
      "Epoch:  773 \tLoss:  0.015649641\n",
      "Epoch:  774 \tLoss:  0.03420996\n",
      "Epoch:  775 \tLoss:  0.005341191\n",
      "Epoch:  776 \tLoss:  0.020815035\n",
      "Epoch:  777 \tLoss:  0.0064766016\n",
      "Epoch:  778 \tLoss:  0.016957879\n",
      "Epoch:  779 \tLoss:  0.005497519\n",
      "Epoch:  780 \tLoss:  0.014349652\n",
      "Epoch:  781 \tLoss:  0.0035155695\n",
      "Epoch:  782 \tLoss:  0.0046741934\n",
      "Epoch:  783 \tLoss:  0.0032780254\n",
      "Epoch:  784 \tLoss:  0.0064625777\n",
      "Epoch:  785 \tLoss:  0.020361794\n",
      "Epoch:  786 \tLoss:  0.010439556\n",
      "Epoch:  787 \tLoss:  0.002665598\n",
      "Epoch:  788 \tLoss:  0.00070856884\n",
      "Epoch:  789 \tLoss:  0.009368105\n",
      "Epoch:  790 \tLoss:  0.0018105097\n",
      "Epoch:  791 \tLoss:  0.0005267784\n",
      "Epoch:  792 \tLoss:  0.01698153\n",
      "Epoch:  793 \tLoss:  0.0015834346\n",
      "Epoch:  794 \tLoss:  0.010284331\n",
      "Epoch:  795 \tLoss:  0.010531526\n",
      "Epoch:  796 \tLoss:  0.017608048\n",
      "Epoch:  797 \tLoss:  0.0018932987\n",
      "Epoch:  798 \tLoss:  0.0048196446\n",
      "Epoch:  799 \tLoss:  0.0057077557\n",
      "Epoch:  800 \tLoss:  0.005564736\n",
      "Epoch:  801 \tLoss:  0.009723395\n",
      "Epoch:  802 \tLoss:  0.012860972\n",
      "Epoch:  803 \tLoss:  0.0036236178\n",
      "Epoch:  804 \tLoss:  0.011308158\n",
      "Epoch:  805 \tLoss:  0.010264583\n",
      "Epoch:  806 \tLoss:  0.004663784\n",
      "Epoch:  807 \tLoss:  0.0022997856\n",
      "Epoch:  808 \tLoss:  0.002551781\n",
      "Epoch:  809 \tLoss:  0.0025517996\n",
      "Epoch:  810 \tLoss:  0.0022656359\n",
      "Epoch:  811 \tLoss:  0.0012988709\n",
      "Epoch:  812 \tLoss:  0.000933066\n",
      "Epoch:  813 \tLoss:  0.00561147\n",
      "Epoch:  814 \tLoss:  0.0006619729\n",
      "Epoch:  815 \tLoss:  0.0025694761\n",
      "Epoch:  816 \tLoss:  0.004699123\n",
      "Epoch:  817 \tLoss:  0.004337008\n",
      "Epoch:  818 \tLoss:  0.002163697\n",
      "Epoch:  819 \tLoss:  0.0012947917\n",
      "Epoch:  820 \tLoss:  0.004185686\n",
      "Epoch:  821 \tLoss:  0.006481654\n",
      "Epoch:  822 \tLoss:  0.0056729605\n",
      "Epoch:  823 \tLoss:  0.0015369933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  824 \tLoss:  0.0032615867\n",
      "Epoch:  825 \tLoss:  0.0068162307\n",
      "Epoch:  826 \tLoss:  0.010479344\n",
      "Epoch:  827 \tLoss:  0.0032130405\n",
      "Epoch:  828 \tLoss:  0.004925417\n",
      "Epoch:  829 \tLoss:  0.007535044\n",
      "Epoch:  830 \tLoss:  0.0025445689\n",
      "Epoch:  831 \tLoss:  0.00048634317\n",
      "Epoch:  832 \tLoss:  0.0003717998\n",
      "Epoch:  833 \tLoss:  0.0036437307\n",
      "Epoch:  834 \tLoss:  0.002684676\n",
      "Epoch:  835 \tLoss:  8.9370646e-05\n",
      "Epoch:  836 \tLoss:  0.0030940017\n",
      "Epoch:  837 \tLoss:  0.005642581\n",
      "Epoch:  838 \tLoss:  0.004628338\n",
      "Epoch:  839 \tLoss:  0.0035284031\n",
      "Epoch:  840 \tLoss:  0.0034570592\n",
      "Epoch:  841 \tLoss:  0.00026228372\n",
      "Epoch:  842 \tLoss:  0.0033680685\n",
      "Epoch:  843 \tLoss:  0.0027161222\n",
      "Epoch:  844 \tLoss:  0.002171942\n",
      "Epoch:  845 \tLoss:  0.00012916047\n",
      "Epoch:  846 \tLoss:  0.001942154\n",
      "Epoch:  847 \tLoss:  0.0020682374\n",
      "Epoch:  848 \tLoss:  0.0015303986\n",
      "Epoch:  849 \tLoss:  0.001173595\n",
      "Epoch:  850 \tLoss:  0.0052133305\n",
      "Epoch:  851 \tLoss:  0.0062641446\n",
      "Epoch:  852 \tLoss:  0.004427388\n",
      "Epoch:  853 \tLoss:  0.0010276609\n",
      "Epoch:  854 \tLoss:  0.0033562891\n",
      "Epoch:  855 \tLoss:  0.0022713859\n",
      "Epoch:  856 \tLoss:  0.003292284\n",
      "Epoch:  857 \tLoss:  0.0018944629\n",
      "Epoch:  858 \tLoss:  0.005044726\n",
      "Epoch:  859 \tLoss:  0.0039516636\n",
      "Epoch:  860 \tLoss:  0.003530967\n",
      "Epoch:  861 \tLoss:  0.0008559399\n",
      "Epoch:  862 \tLoss:  0.0026632412\n",
      "Epoch:  863 \tLoss:  0.001789745\n",
      "Epoch:  864 \tLoss:  0.0030998\n",
      "Epoch:  865 \tLoss:  0.0041517843\n",
      "Epoch:  866 \tLoss:  0.00041403808\n",
      "Epoch:  867 \tLoss:  0.00035110628\n",
      "Epoch:  868 \tLoss:  0.0012589991\n",
      "Epoch:  869 \tLoss:  0.0020853714\n",
      "Epoch:  870 \tLoss:  0.00048238318\n",
      "Epoch:  871 \tLoss:  0.00073405914\n",
      "Epoch:  872 \tLoss:  0.00018902402\n",
      "Epoch:  873 \tLoss:  0.00031997496\n",
      "Epoch:  874 \tLoss:  0.0028030844\n",
      "Epoch:  875 \tLoss:  0.0034559797\n",
      "Epoch:  876 \tLoss:  5.4959673e-05\n",
      "Epoch:  877 \tLoss:  0.00022168132\n",
      "Epoch:  878 \tLoss:  0.0019730586\n",
      "Epoch:  879 \tLoss:  0.003014407\n",
      "Epoch:  880 \tLoss:  0.0007698301\n",
      "Epoch:  881 \tLoss:  0.0017453469\n",
      "Epoch:  882 \tLoss:  0.0010354947\n",
      "Epoch:  883 \tLoss:  0.0008219066\n",
      "Epoch:  884 \tLoss:  0.0017106547\n",
      "Epoch:  885 \tLoss:  0.0005679629\n",
      "Epoch:  886 \tLoss:  0.0010270055\n",
      "Epoch:  887 \tLoss:  0.0014230246\n",
      "Epoch:  888 \tLoss:  0.0012069365\n",
      "Epoch:  889 \tLoss:  0.00036669476\n",
      "Epoch:  890 \tLoss:  0.0013609729\n",
      "Epoch:  891 \tLoss:  0.0004593304\n",
      "Epoch:  892 \tLoss:  0.00092769956\n",
      "Epoch:  893 \tLoss:  0.00020617648\n",
      "Epoch:  894 \tLoss:  0.00050880347\n",
      "Epoch:  895 \tLoss:  0.00028658233\n",
      "Epoch:  896 \tLoss:  0.00037348774\n",
      "Epoch:  897 \tLoss:  2.2317312e-05\n",
      "Epoch:  898 \tLoss:  7.4882e-05\n",
      "Epoch:  899 \tLoss:  0.0002295555\n",
      "Epoch:  900 \tLoss:  3.0663192e-05\n",
      "Epoch:  901 \tLoss:  5.272893e-05\n",
      "Epoch:  902 \tLoss:  0.00011727256\n",
      "Epoch:  903 \tLoss:  6.66594e-05\n",
      "Epoch:  904 \tLoss:  1.0300413e-05\n",
      "Epoch:  905 \tLoss:  2.1649124e-05\n",
      "Epoch:  906 \tLoss:  7.851411e-05\n",
      "Epoch:  907 \tLoss:  6.753605e-05\n",
      "Epoch:  908 \tLoss:  1.673487e-05\n",
      "Epoch:  909 \tLoss:  7.000919e-06\n",
      "Epoch:  910 \tLoss:  5.4758362e-05\n",
      "Epoch:  911 \tLoss:  1.8463907e-05\n",
      "Epoch:  912 \tLoss:  1.46821985e-05\n",
      "Epoch:  913 \tLoss:  3.4933357e-05\n",
      "Epoch:  914 \tLoss:  3.5745383e-05\n",
      "Epoch:  915 \tLoss:  3.5533274e-05\n",
      "Epoch:  916 \tLoss:  4.5040062e-05\n",
      "Epoch:  917 \tLoss:  8.21158e-06\n",
      "Epoch:  918 \tLoss:  1.2744422e-06\n",
      "Epoch:  919 \tLoss:  1.43527e-06\n",
      "Epoch:  920 \tLoss:  3.7347047e-05\n",
      "Epoch:  921 \tLoss:  1.1342265e-05\n",
      "Epoch:  922 \tLoss:  2.4087058e-06\n",
      "Epoch:  923 \tLoss:  3.131514e-06\n",
      "Epoch:  924 \tLoss:  1.1570963e-05\n",
      "Epoch:  925 \tLoss:  2.8753646e-05\n",
      "Epoch:  926 \tLoss:  6.8876e-05\n",
      "Epoch:  927 \tLoss:  3.7402468e-05\n",
      "Epoch:  928 \tLoss:  5.041562e-06\n",
      "Epoch:  929 \tLoss:  3.7666076e-05\n",
      "Epoch:  930 \tLoss:  0.00011443837\n",
      "Epoch:  931 \tLoss:  6.365454e-05\n",
      "Epoch:  932 \tLoss:  5.4313805e-05\n",
      "Epoch:  933 \tLoss:  8.3625055e-05\n",
      "Epoch:  934 \tLoss:  7.804764e-05\n",
      "Epoch:  935 \tLoss:  4.5877536e-05\n",
      "Epoch:  936 \tLoss:  9.899428e-06\n",
      "Epoch:  937 \tLoss:  4.2648404e-05\n",
      "Epoch:  938 \tLoss:  9.986608e-06\n",
      "Epoch:  939 \tLoss:  7.0636e-05\n",
      "Epoch:  940 \tLoss:  2.3602817e-05\n",
      "Epoch:  941 \tLoss:  6.66068e-05\n",
      "Epoch:  942 \tLoss:  5.7908095e-05\n",
      "Epoch:  943 \tLoss:  2.3965775e-05\n",
      "Epoch:  944 \tLoss:  7.0792354e-05\n",
      "Epoch:  945 \tLoss:  7.272593e-05\n",
      "Epoch:  946 \tLoss:  2.9876643e-05\n",
      "Epoch:  947 \tLoss:  2.9973453e-06\n",
      "Epoch:  948 \tLoss:  1.8728679e-05\n",
      "Epoch:  949 \tLoss:  2.3273016e-05\n",
      "Epoch:  950 \tLoss:  3.4093347e-05\n",
      "Epoch:  951 \tLoss:  3.0938318e-05\n",
      "Epoch:  952 \tLoss:  1.6522921e-05\n",
      "Epoch:  953 \tLoss:  4.4555592e-05\n",
      "Epoch:  954 \tLoss:  3.7030288e-05\n",
      "Epoch:  955 \tLoss:  6.8129957e-06\n",
      "Epoch:  956 \tLoss:  5.2184536e-05\n",
      "Epoch:  957 \tLoss:  7.628682e-05\n",
      "Epoch:  958 \tLoss:  6.0264283e-06\n",
      "Epoch:  959 \tLoss:  5.766138e-06\n",
      "Epoch:  960 \tLoss:  7.37011e-05\n",
      "Epoch:  961 \tLoss:  2.947155e-05\n",
      "Epoch:  962 \tLoss:  2.6273796e-05\n",
      "Epoch:  963 \tLoss:  2.5546648e-05\n",
      "Epoch:  964 \tLoss:  5.2452004e-05\n",
      "Epoch:  965 \tLoss:  5.4090342e-05\n",
      "Epoch:  966 \tLoss:  6.229561e-05\n",
      "Epoch:  967 \tLoss:  8.9894675e-06\n",
      "Epoch:  968 \tLoss:  5.5540964e-05\n",
      "Epoch:  969 \tLoss:  7.093144e-05\n",
      "Epoch:  970 \tLoss:  6.405783e-05\n",
      "Epoch:  971 \tLoss:  3.3333781e-06\n",
      "Epoch:  972 \tLoss:  4.7806476e-05\n",
      "Epoch:  973 \tLoss:  5.6104473e-06\n",
      "Epoch:  974 \tLoss:  4.0703504e-05\n",
      "Epoch:  975 \tLoss:  8.829555e-05\n",
      "Epoch:  976 \tLoss:  9.291591e-06\n",
      "Epoch:  977 \tLoss:  9.502703e-05\n",
      "Epoch:  978 \tLoss:  4.1419116e-06\n",
      "Epoch:  979 \tLoss:  1.2240664e-05\n",
      "Epoch:  980 \tLoss:  1.0642048e-05\n",
      "Epoch:  981 \tLoss:  5.289034e-05\n",
      "Epoch:  982 \tLoss:  7.087329e-05\n",
      "Epoch:  983 \tLoss:  8.527875e-05\n",
      "Epoch:  984 \tLoss:  3.0119372e-06\n",
      "Epoch:  985 \tLoss:  5.816421e-05\n",
      "Epoch:  986 \tLoss:  1.0280783e-05\n",
      "Epoch:  987 \tLoss:  5.330633e-05\n",
      "Epoch:  988 \tLoss:  6.855446e-05\n",
      "Epoch:  989 \tLoss:  1.6302758e-05\n",
      "Epoch:  990 \tLoss:  1.9392908e-05\n",
      "Epoch:  991 \tLoss:  2.3458502e-05\n",
      "Epoch:  992 \tLoss:  1.726883e-05\n",
      "Epoch:  993 \tLoss:  5.0004746e-07\n",
      "Epoch:  994 \tLoss:  1.4059646e-05\n",
      "Epoch:  995 \tLoss:  2.1142194e-05\n",
      "Epoch:  996 \tLoss:  1.7187805e-05\n",
      "Epoch:  997 \tLoss:  8.283154e-06\n",
      "Epoch:  998 \tLoss:  0.00010323514\n",
      "Epoch:  999 \tLoss:  1.3354864e-05\n",
      "Epoch:  1000 \tLoss:  1.9104926e-05\n",
      "Epoch:  1001 \tLoss:  6.586555e-05\n",
      "Epoch:  1002 \tLoss:  2.3334462e-05\n",
      "Epoch:  1003 \tLoss:  3.513749e-06\n",
      "Epoch:  1004 \tLoss:  3.4921366e-05\n",
      "Epoch:  1005 \tLoss:  5.0331946e-06\n",
      "Epoch:  1006 \tLoss:  3.204499e-06\n",
      "Epoch:  1007 \tLoss:  5.6006247e-06\n",
      "Epoch:  1008 \tLoss:  5.0441668e-06\n",
      "Epoch:  1009 \tLoss:  3.7657384e-05\n",
      "Epoch:  1010 \tLoss:  4.0464936e-05\n",
      "Epoch:  1011 \tLoss:  3.2503565e-05\n",
      "Epoch:  1012 \tLoss:  3.0859723e-05\n",
      "Epoch:  1013 \tLoss:  1.6561244e-06\n",
      "Epoch:  1014 \tLoss:  1.3186436e-06\n",
      "Epoch:  1015 \tLoss:  5.4377633e-05\n",
      "Epoch:  1016 \tLoss:  4.8673886e-05\n",
      "Epoch:  1017 \tLoss:  2.535362e-05\n",
      "Epoch:  1018 \tLoss:  5.3671312e-05\n",
      "Epoch:  1019 \tLoss:  2.5928523e-05\n",
      "Epoch:  1020 \tLoss:  7.4804993e-06\n",
      "Epoch:  1021 \tLoss:  6.445124e-05\n",
      "Epoch:  1022 \tLoss:  9.970664e-05\n",
      "Epoch:  1023 \tLoss:  7.921606e-06\n",
      "Epoch:  1024 \tLoss:  6.935067e-05\n",
      "Epoch:  1025 \tLoss:  5.064149e-05\n",
      "Epoch:  1026 \tLoss:  8.7932756e-05\n",
      "Epoch:  1027 \tLoss:  3.53597e-07\n",
      "Epoch:  1028 \tLoss:  9.919469e-05\n",
      "Epoch:  1029 \tLoss:  8.042628e-05\n",
      "Epoch:  1030 \tLoss:  1.2045042e-05\n",
      "Epoch:  1031 \tLoss:  2.8077411e-05\n",
      "Epoch:  1032 \tLoss:  5.656024e-06\n",
      "Epoch:  1033 \tLoss:  6.400829e-05\n",
      "Epoch:  1034 \tLoss:  1.4096324e-05\n",
      "Epoch:  1035 \tLoss:  2.0327876e-05\n",
      "Epoch:  1036 \tLoss:  2.5228088e-05\n",
      "Epoch:  1037 \tLoss:  2.0271633e-05\n",
      "Epoch:  1038 \tLoss:  1.2545257e-05\n",
      "Epoch:  1039 \tLoss:  6.825312e-05\n",
      "Epoch:  1040 \tLoss:  2.1598651e-05\n",
      "Epoch:  1041 \tLoss:  3.355179e-05\n",
      "Epoch:  1042 \tLoss:  5.4214834e-06\n",
      "Epoch:  1043 \tLoss:  8.297531e-06\n",
      "Epoch:  1044 \tLoss:  3.4402103e-05\n",
      "Epoch:  1045 \tLoss:  5.53536e-05\n",
      "Epoch:  1046 \tLoss:  1.2380915e-05\n",
      "Epoch:  1047 \tLoss:  2.6079433e-06\n",
      "Epoch:  1048 \tLoss:  2.7103419e-05\n",
      "Epoch:  1049 \tLoss:  6.705511e-05\n",
      "Epoch:  1050 \tLoss:  1.6760634e-05\n",
      "Epoch:  1051 \tLoss:  5.2186515e-05\n",
      "Epoch:  1052 \tLoss:  1.3393881e-05\n",
      "Epoch:  1053 \tLoss:  2.4509336e-05\n",
      "Epoch:  1054 \tLoss:  7.713554e-05\n",
      "Epoch:  1055 \tLoss:  4.2523316e-05\n",
      "Epoch:  1056 \tLoss:  4.6326633e-05\n",
      "Epoch:  1057 \tLoss:  2.8155664e-05\n",
      "Epoch:  1058 \tLoss:  1.1755197e-05\n",
      "Epoch:  1059 \tLoss:  1.7678329e-05\n",
      "Epoch:  1060 \tLoss:  4.1302497e-05\n",
      "Epoch:  1061 \tLoss:  7.5958334e-05\n",
      "Epoch:  1062 \tLoss:  2.7666567e-05\n",
      "Epoch:  1063 \tLoss:  2.990591e-05\n",
      "Epoch:  1064 \tLoss:  7.5575663e-06\n",
      "Epoch:  1065 \tLoss:  5.303853e-06\n",
      "Epoch:  1066 \tLoss:  6.824747e-05\n",
      "Epoch:  1067 \tLoss:  3.3516088e-05\n",
      "Epoch:  1068 \tLoss:  3.1536903e-05\n",
      "Epoch:  1069 \tLoss:  1.9779305e-05\n",
      "Epoch:  1070 \tLoss:  1.6055594e-05\n",
      "Epoch:  1071 \tLoss:  4.3645596e-05\n",
      "Epoch:  1072 \tLoss:  3.48089e-05\n",
      "Epoch:  1073 \tLoss:  1.5090001e-05\n",
      "Epoch:  1074 \tLoss:  3.881813e-05\n",
      "Epoch:  1075 \tLoss:  3.3874785e-05\n",
      "Epoch:  1076 \tLoss:  1.833996e-05\n",
      "Epoch:  1077 \tLoss:  2.4058263e-05\n",
      "Epoch:  1078 \tLoss:  2.6144811e-05\n",
      "Epoch:  1079 \tLoss:  1.6311162e-05\n",
      "Epoch:  1080 \tLoss:  2.6430884e-05\n",
      "Epoch:  1081 \tLoss:  9.090072e-06\n",
      "Epoch:  1082 \tLoss:  1.6013655e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1083 \tLoss:  5.0589813e-05\n",
      "Epoch:  1084 \tLoss:  5.8182617e-05\n",
      "Epoch:  1085 \tLoss:  3.7451166e-05\n",
      "Epoch:  1086 \tLoss:  1.879051e-05\n",
      "Epoch:  1087 \tLoss:  1.1639233e-05\n",
      "Epoch:  1088 \tLoss:  1.3722602e-05\n",
      "Epoch:  1089 \tLoss:  2.3638e-05\n",
      "Epoch:  1090 \tLoss:  4.8824513e-06\n",
      "Epoch:  1091 \tLoss:  3.4671102e-05\n",
      "Epoch:  1092 \tLoss:  4.1270832e-06\n",
      "Epoch:  1093 \tLoss:  4.138281e-06\n",
      "Epoch:  1094 \tLoss:  2.7686721e-05\n",
      "Epoch:  1095 \tLoss:  1.7802726e-05\n",
      "Epoch:  1096 \tLoss:  7.2748517e-06\n",
      "Epoch:  1097 \tLoss:  5.07839e-05\n",
      "Epoch:  1098 \tLoss:  3.6832032e-05\n",
      "Epoch:  1099 \tLoss:  3.724327e-05\n",
      "Epoch:  1100 \tLoss:  7.946562e-05\n",
      "Epoch:  1101 \tLoss:  3.6284036e-05\n",
      "Epoch:  1102 \tLoss:  2.247018e-05\n",
      "Epoch:  1103 \tLoss:  7.574858e-05\n",
      "Epoch:  1104 \tLoss:  9.849355e-06\n",
      "Epoch:  1105 \tLoss:  8.732287e-05\n",
      "Epoch:  1106 \tLoss:  4.149726e-05\n",
      "Epoch:  1107 \tLoss:  1.8542582e-05\n",
      "Epoch:  1108 \tLoss:  4.4132255e-05\n",
      "Epoch:  1109 \tLoss:  5.2555675e-05\n",
      "Epoch:  1110 \tLoss:  2.410695e-05\n",
      "Epoch:  1111 \tLoss:  5.055881e-05\n",
      "Epoch:  1112 \tLoss:  4.0022176e-05\n",
      "Epoch:  1113 \tLoss:  2.1019245e-05\n",
      "Epoch:  1114 \tLoss:  4.3183027e-05\n",
      "Epoch:  1115 \tLoss:  1.9157895e-05\n",
      "Epoch:  1116 \tLoss:  6.74334e-05\n",
      "Epoch:  1117 \tLoss:  4.559299e-05\n",
      "Epoch:  1118 \tLoss:  2.8861577e-05\n",
      "Epoch:  1119 \tLoss:  7.455965e-07\n",
      "Epoch:  1120 \tLoss:  3.8815557e-05\n",
      "Epoch:  1121 \tLoss:  6.41817e-05\n",
      "Epoch:  1122 \tLoss:  1.99262e-05\n",
      "Epoch:  1123 \tLoss:  6.5689106e-05\n",
      "Epoch:  1124 \tLoss:  3.1477728e-05\n",
      "Epoch:  1125 \tLoss:  3.7348873e-05\n",
      "Epoch:  1126 \tLoss:  6.25744e-05\n",
      "Epoch:  1127 \tLoss:  5.223255e-05\n",
      "Epoch:  1128 \tLoss:  2.1512838e-05\n",
      "Epoch:  1129 \tLoss:  2.2117652e-05\n",
      "Epoch:  1130 \tLoss:  1.9873616e-05\n",
      "Epoch:  1131 \tLoss:  6.8241025e-05\n",
      "Epoch:  1132 \tLoss:  6.0983737e-05\n",
      "Epoch:  1133 \tLoss:  4.722184e-06\n",
      "Epoch:  1134 \tLoss:  3.748691e-05\n",
      "Epoch:  1135 \tLoss:  0.00010307014\n",
      "Epoch:  1136 \tLoss:  9.779194e-05\n",
      "Epoch:  1137 \tLoss:  2.3768665e-05\n",
      "Epoch:  1138 \tLoss:  2.136665e-05\n",
      "Epoch:  1139 \tLoss:  9.5522555e-06\n",
      "Epoch:  1140 \tLoss:  1.9472325e-05\n",
      "Epoch:  1141 \tLoss:  2.3974993e-05\n",
      "Epoch:  1142 \tLoss:  8.275853e-05\n",
      "Epoch:  1143 \tLoss:  8.1963444e-05\n",
      "Epoch:  1144 \tLoss:  5.0972187e-05\n",
      "Epoch:  1145 \tLoss:  2.6470778e-05\n",
      "Epoch:  1146 \tLoss:  3.6569167e-05\n",
      "Epoch:  1147 \tLoss:  2.358087e-06\n",
      "Epoch:  1148 \tLoss:  2.7929811e-05\n",
      "Epoch:  1149 \tLoss:  3.133303e-05\n",
      "Epoch:  1150 \tLoss:  6.5630666e-06\n",
      "Epoch:  1151 \tLoss:  1.8740284e-05\n",
      "Epoch:  1152 \tLoss:  2.8830254e-06\n",
      "Epoch:  1153 \tLoss:  2.319747e-05\n",
      "Epoch:  1154 \tLoss:  2.835547e-05\n",
      "Epoch:  1155 \tLoss:  2.5514455e-06\n",
      "Epoch:  1156 \tLoss:  4.232399e-05\n",
      "Epoch:  1157 \tLoss:  1.9226816e-05\n",
      "Epoch:  1158 \tLoss:  8.4826606e-05\n",
      "Epoch:  1159 \tLoss:  4.9391252e-05\n",
      "Epoch:  1160 \tLoss:  6.8770896e-07\n",
      "Epoch:  1161 \tLoss:  4.062071e-05\n",
      "Epoch:  1162 \tLoss:  4.8311704e-05\n",
      "Epoch:  1163 \tLoss:  3.1293184e-05\n",
      "Epoch:  1164 \tLoss:  3.3827808e-05\n",
      "Epoch:  1165 \tLoss:  4.2041833e-05\n",
      "Epoch:  1166 \tLoss:  6.699082e-05\n",
      "Epoch:  1167 \tLoss:  1.17096715e-05\n",
      "Epoch:  1168 \tLoss:  1.8139122e-05\n",
      "Epoch:  1169 \tLoss:  2.8090159e-05\n",
      "Epoch:  1170 \tLoss:  3.8781625e-05\n",
      "Epoch:  1171 \tLoss:  2.6723697e-05\n",
      "Epoch:  1172 \tLoss:  9.587166e-06\n",
      "Epoch:  1173 \tLoss:  3.0768126e-05\n",
      "Epoch:  1174 \tLoss:  2.4262965e-05\n",
      "Epoch:  1175 \tLoss:  3.2262546e-05\n",
      "Epoch:  1176 \tLoss:  1.3856668e-05\n",
      "Epoch:  1177 \tLoss:  4.6458004e-05\n",
      "Epoch:  1178 \tLoss:  6.545021e-05\n",
      "Epoch:  1179 \tLoss:  8.7496985e-05\n",
      "Epoch:  1180 \tLoss:  3.7515947e-05\n",
      "Epoch:  1181 \tLoss:  1.999415e-05\n",
      "Epoch:  1182 \tLoss:  1.5835147e-05\n",
      "Epoch:  1183 \tLoss:  6.8511363e-06\n",
      "Epoch:  1184 \tLoss:  1.588987e-05\n",
      "Epoch:  1185 \tLoss:  5.2305404e-07\n",
      "Epoch:  1186 \tLoss:  1.8194987e-05\n",
      "Epoch:  1187 \tLoss:  5.3493808e-05\n",
      "Epoch:  1188 \tLoss:  3.5511497e-05\n",
      "Epoch:  1189 \tLoss:  3.1618692e-05\n",
      "Epoch:  1190 \tLoss:  2.2159395e-05\n",
      "Epoch:  1191 \tLoss:  1.3882971e-05\n",
      "Epoch:  1192 \tLoss:  4.8766826e-05\n",
      "Epoch:  1193 \tLoss:  1.2137745e-05\n",
      "Epoch:  1194 \tLoss:  9.0116315e-05\n",
      "Epoch:  1195 \tLoss:  5.7363402e-05\n",
      "Epoch:  1196 \tLoss:  2.2844324e-06\n",
      "Epoch:  1197 \tLoss:  4.393125e-05\n",
      "Epoch:  1198 \tLoss:  8.652788e-05\n",
      "Epoch:  1199 \tLoss:  4.6449204e-05\n",
      "Epoch:  1200 \tLoss:  2.1882384e-05\n",
      "Epoch:  1201 \tLoss:  1.7448634e-05\n",
      "Epoch:  1202 \tLoss:  4.6739555e-05\n",
      "Epoch:  1203 \tLoss:  5.2460335e-05\n",
      "Epoch:  1204 \tLoss:  3.599732e-05\n",
      "Epoch:  1205 \tLoss:  3.297715e-06\n",
      "Epoch:  1206 \tLoss:  4.24817e-05\n",
      "Epoch:  1207 \tLoss:  4.414816e-05\n",
      "Epoch:  1208 \tLoss:  7.892227e-05\n",
      "Epoch:  1209 \tLoss:  2.5114387e-05\n",
      "Epoch:  1210 \tLoss:  4.0542065e-05\n",
      "Epoch:  1211 \tLoss:  4.1628955e-05\n",
      "Epoch:  1212 \tLoss:  0.000104433624\n",
      "Epoch:  1213 \tLoss:  4.374142e-05\n",
      "Epoch:  1214 \tLoss:  1.6099577e-05\n",
      "Epoch:  1215 \tLoss:  2.465675e-05\n",
      "Epoch:  1216 \tLoss:  4.3985536e-05\n",
      "Epoch:  1217 \tLoss:  8.282678e-05\n",
      "Epoch:  1218 \tLoss:  0.00010361547\n",
      "Epoch:  1219 \tLoss:  8.659574e-06\n",
      "Epoch:  1220 \tLoss:  7.773874e-05\n",
      "Epoch:  1221 \tLoss:  5.041013e-05\n",
      "Epoch:  1222 \tLoss:  7.477829e-05\n",
      "Epoch:  1223 \tLoss:  1.4108387e-05\n",
      "Epoch:  1224 \tLoss:  7.616036e-06\n",
      "Epoch:  1225 \tLoss:  2.1995278e-05\n",
      "Epoch:  1226 \tLoss:  7.0476e-05\n",
      "Epoch:  1227 \tLoss:  2.4596997e-05\n",
      "Epoch:  1228 \tLoss:  1.2081684e-05\n",
      "Epoch:  1229 \tLoss:  5.8591875e-05\n",
      "Epoch:  1230 \tLoss:  0.00010308243\n",
      "Epoch:  1231 \tLoss:  1.4567104e-05\n",
      "Epoch:  1232 \tLoss:  4.9526072e-05\n",
      "Epoch:  1233 \tLoss:  3.3334058e-05\n",
      "Epoch:  1234 \tLoss:  2.1048865e-05\n",
      "Epoch:  1235 \tLoss:  1.9283383e-05\n",
      "Epoch:  1236 \tLoss:  6.066988e-05\n",
      "Epoch:  1237 \tLoss:  2.190093e-05\n",
      "Epoch:  1238 \tLoss:  3.4477947e-05\n",
      "Epoch:  1239 \tLoss:  5.397928e-05\n",
      "Epoch:  1240 \tLoss:  5.038942e-05\n",
      "Epoch:  1241 \tLoss:  6.9947026e-05\n",
      "Epoch:  1242 \tLoss:  6.329544e-05\n",
      "Epoch:  1243 \tLoss:  1.16505835e-05\n",
      "Epoch:  1244 \tLoss:  2.1076085e-05\n",
      "Epoch:  1245 \tLoss:  1.4677644e-06\n",
      "Epoch:  1246 \tLoss:  2.47173e-06\n",
      "Epoch:  1247 \tLoss:  6.213393e-05\n",
      "Epoch:  1248 \tLoss:  6.1607294e-05\n",
      "Epoch:  1249 \tLoss:  3.2218086e-06\n",
      "Epoch:  1250 \tLoss:  8.972856e-06\n",
      "Epoch:  1251 \tLoss:  3.104705e-05\n",
      "Epoch:  1252 \tLoss:  3.2858807e-05\n",
      "Epoch:  1253 \tLoss:  1.6511585e-05\n",
      "Epoch:  1254 \tLoss:  3.823817e-05\n",
      "Epoch:  1255 \tLoss:  7.085506e-05\n",
      "Epoch:  1256 \tLoss:  1.5070131e-05\n",
      "Epoch:  1257 \tLoss:  2.0643201e-05\n",
      "Epoch:  1258 \tLoss:  3.5609795e-05\n",
      "Epoch:  1259 \tLoss:  5.545179e-05\n",
      "Epoch:  1260 \tLoss:  9.561809e-06\n",
      "Epoch:  1261 \tLoss:  1.5608493e-05\n",
      "Epoch:  1262 \tLoss:  2.0773929e-05\n",
      "Epoch:  1263 \tLoss:  4.6940186e-05\n",
      "Epoch:  1264 \tLoss:  4.2600877e-06\n",
      "Epoch:  1265 \tLoss:  9.515294e-06\n",
      "Epoch:  1266 \tLoss:  5.7288322e-05\n",
      "Epoch:  1267 \tLoss:  5.118743e-05\n",
      "Epoch:  1268 \tLoss:  7.5370954e-05\n",
      "Epoch:  1269 \tLoss:  3.0116316e-05\n",
      "Epoch:  1270 \tLoss:  7.550847e-05\n",
      "Epoch:  1271 \tLoss:  7.634117e-05\n",
      "Epoch:  1272 \tLoss:  3.052046e-07\n",
      "Epoch:  1273 \tLoss:  6.479808e-06\n",
      "Epoch:  1274 \tLoss:  3.276003e-05\n",
      "Epoch:  1275 \tLoss:  9.8199e-05\n",
      "Epoch:  1276 \tLoss:  9.440177e-05\n",
      "Epoch:  1277 \tLoss:  7.7342585e-05\n",
      "Epoch:  1278 \tLoss:  1.7825434e-05\n",
      "Learning rate: 0.0009999999999992298\tMax distance: 3.942766252373886e-14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1000,), dtype=int32, numpy=\n",
       "array([1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "       1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
       "       0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 1])>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.train(input_data)\n",
    "y = knn(input_data)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bef2f092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Мощность первого класса:  500 \tМощность второго класса:  500\n"
     ]
    }
   ],
   "source": [
    "n = plt.hist(y.numpy(), )\n",
    "plt.show()\n",
    "print('Мощность первого класса: ', int(n[0][0]), '\\tМощность второго класса: ',  int(n[0][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd553d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7015748"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Средний коэффициент силуэта для евклидова расстояния\n",
    "metrics.silhouette_score(input_data, y, metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70909596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9642009"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Средний коэффициент силуэта для косинусного сходства\n",
    "metrics.silhouette_score(input_data, y, metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28d5132c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4400800708653689"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Индекс Дэвиса-Болдина\n",
    "metrics.davies_bouldin_score(input_data, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b69cf57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
